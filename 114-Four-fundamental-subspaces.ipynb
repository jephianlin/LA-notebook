{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四大基礎子空間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lingeo import random_good_matrix, random_int_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that if $V$ is a subspace in $\\mathbb{R}^n$, then its orthogonal complement is  \n",
    "$$V^\\perp = \\{{\\bf w}\\in\\mathbb{R}^n : \\langle{\\bf w},{\\bf v}\\rangle = 0 \\text{ for all }{\\bf v}\\in V\\}.$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $V = \\operatorname{span}(S)$ for some finite set $S$.  \n",
    "(We will show in the next chapter that in fact every subspace in $\\mathbb{R}^n$ can be generated by a finite set.)  \n",
    "Then every matrix ${\\bf b}$ can be written as a unique representation  \n",
    "$${\\bf b} = {\\bf w} + {\\bf h}$$\n",
    "such that ${\\bf w}\\in V$ and ${\\bf h}\\in V^\\perp$.  \n",
    "Also, $(V^\\perp)^\\perp = V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ be an $m\\times n$ matrix.  \n",
    "Let $R$ be the reduced echelon form of $A$ and $r$ the number of its pivots.  \n",
    "Consider the augmented matrix $\\left[\\begin{array}{c|c} A & I_m \\end{array}\\right]$.  \n",
    "Let $\\left[\\begin{array}{c|c} R & B \\end{array}\\right]$ be its reduced echelon form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then $\\operatorname{Row}(A)$ and $\\operatorname{ker}(A)$ are subspaces in $\\mathbb{R}^n$ and they are the orthogonal complement of each other.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta_R = \\{{\\bf r}_1,\\ldots,{\\bf r}_r\\}$ be the set of nonzero rows in $R$.  \n",
    "Then $\\operatorname{Row}(A) = \\operatorname{span}(\\beta_R)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta_K = \\{{\\bf h}_1, \\ldots, {\\bf h}_{n-r}\\}$ be the set of homogeneous solutions solved by setting one free variable as $1$ and others as $0$.  \n",
    "Then $\\operatorname{ker}(A) = \\operatorname{span}(\\beta_K)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, $\\operatorname{Col}(A)$ and $\\operatorname{ker}(A^\\top)$ are subspaces in $\\mathbb{R}^m$ and they are the orthogonal complement of each other.  \n",
    "The subspace $\\operatorname{ker}(A^\\top)$ is called the **left kernel** of $A$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta_C = \\{ {\\bf u}_1,\\ldots, {\\bf u}_r \\}$ be the set of columns of $A$ corresponding to the pivots of $R$.  \n",
    "Then $\\operatorname{Col}(A) = \\operatorname{span}(\\beta_C)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta_L = \\{ {\\bf b}_1,\\ldots,{\\bf b}_{m-r} \\}$ be the last $m-r$ rows in $B$.  \n",
    "Then $\\operatorname{ker}(A^\\top) = \\operatorname{span}(\\beta_L)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call each of $\\beta_R$, $\\beta_K$, $\\beta_C$, $\\beta_L$ the **standard basis** of the corresponding subspace.  \n",
    "(We have not yet mentioned what is a basis, so you may view them as standard generating sets of the corresponding subspaces.  \n",
    "But we will prove they are really a basis in the future.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side stories\n",
    "- generator of $V^\\perp$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "\n",
    "執行下方程式碼。  \n",
    "矩陣 $\\left[\\begin{array}{c|c} R & B \\end{array}\\right]$ 是 $\\left[\\begin{array}{c|c} A & I \\end{array}\\right]$ 的最簡階梯形式矩陣。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### code\n",
    "set_random_seed(0)\n",
    "print_ans = False\n",
    "m,n,r = 3,5,2\n",
    "A, R, pivots = random_good_matrix(m,n,r, return_answer=True)\n",
    "\n",
    "AI = A.augment(identity_matrix(3), subdivide=True)\n",
    "RB = AI.rref()\n",
    "B = RB[:,n:]\n",
    "print(\"[ A | I ] =\")\n",
    "show(AI)\n",
    "print(\"[ R | B ] =\")\n",
    "show(RB)\n",
    "\n",
    "if print_ans:\n",
    "    Rp = R[:r,:] ### r x n\n",
    "    H = zero_matrix(Rp.base_ring(), n, n-r) ### n x (n-r)\n",
    "    free = [i for i in range(n) if i not in pivots]\n",
    "    H[pivots] = -Rp[:, free]\n",
    "    H[free] = identity_matrix(n-r)\n",
    "    C = A[:, pivots] ### m x r\n",
    "    Bp = B[r:,:] ### (m-r) x m\n",
    "    print(\"beta R = rows of\")\n",
    "    show(Rp)\n",
    "    print(\"beta K = columns of\")\n",
    "    show(H)\n",
    "    print(\"beta C = columns of\")\n",
    "    show(C)\n",
    "    print(\"beta L = rows of\")\n",
    "    show(Bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1(a)\n",
    "\n",
    "求 $\\beta_R$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1(b)\n",
    "\n",
    "求 $\\beta_K$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1(c)\n",
    "\n",
    "求 $\\beta_C$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1(d)\n",
    "\n",
    "求 $\\beta_L$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "\n",
    "執行以下程式碼。  \n",
    "令 $S = \\{ {\\bf r}_1, {\\bf r}_2, {\\bf r}_3 \\}$ 為矩陣 $A$ 的各列向量  \n",
    "且 $V = \\operatorname{span}(S)$。  \n",
    "求 $T$ 使得 $V^\\perp = \\operatorname{span}(T)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code\n",
    "set_random_seed(0)\n",
    "print_ans = False\n",
    "m,n,r = 3,5,2\n",
    "A, R, pivots = random_good_matrix(m,n,r, return_answer=True)\n",
    "print(\"A =\")\n",
    "show(A)\n",
    "\n",
    "if print_ans:\n",
    "    H = zero_matrix(R.base_ring(), n, n-r)\n",
    "    free = [i for i in range(n) if i not in pivots]\n",
    "    H[pivots,:] = R[:r,free]\n",
    "    H[free,:] = identity_matrix(n-r)\n",
    "    print(\"T = the set of columns of\")\n",
    "    show(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3\n",
    "\n",
    "執行以下程式碼。  \n",
    "令 $S = \\{ {\\bf u}_1, {\\bf u}_2 \\}$ 為矩陣 $A$ 的各行向量  \n",
    "且 $V = \\operatorname{span}(S)$。  \n",
    "求 ${\\bf b}$ 在 $V$ 上的投影。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code\n",
    "set_random_seed(0)\n",
    "print_ans = False\n",
    "A = random_good_matrix(5,2,2)\n",
    "print(\"A =\")\n",
    "show(A)\n",
    "\n",
    "b = vector(random_int_list(5))\n",
    "print(\"b =\", b)\n",
    "\n",
    "if print_ans:\n",
    "    ATAinv = (A.transpose() * A).inverse()\n",
    "    w = A * ATAinv * A.transpose() * b\n",
    "    print(\"projection =\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 4\n",
    "\n",
    "執行以下程式碼。  \n",
    "令 $S = \\{ {\\bf u}_1, {\\bf u}_2, {\\bf u}_3 \\}$ 為矩陣 $A$ 的各行向量  \n",
    "且 $V = \\operatorname{span}(S)$。  \n",
    "求 ${\\bf b}$ 在 $V$ 上的投影。  \n",
    "（如果你發覺 $A^\\top A$ 不可逆的話﹐  \n",
    "記得把一些不重要的向量拿掉。  \n",
    "只要生成出來是 $V$，  \n",
    "不一定要把全部向量放進去。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code\n",
    "set_random_seed(0)\n",
    "print_ans = False\n",
    "A = random_good_matrix(5,3,2)\n",
    "print(\"A =\")\n",
    "show(A)\n",
    "\n",
    "b = vector(random_int_list(5))\n",
    "print(\"b =\", b)\n",
    "\n",
    "if print_ans:\n",
    "    Ap = A[:,pivots]\n",
    "    ATAinv = (Ap.transpose() * Ap).inverse()\n",
    "    w = Ap * ATAinv * Ap.transpose() * b\n",
    "    print(\"projection =\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "\n",
    "令 $A$ 為一 $m\\times n$ 矩陣。  \n",
    "我們知道高斯消去法不會影響列空間，  \n",
    "因此自然地 $\\operatorname{Row}(A) = \\operatorname{span}(\\beta_R)$。  \n",
    "\n",
    "以下我們說明為什麼 $\\operatorname{ker}(A) = \\operatorname{span}(\\beta_K)$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5(a)\n",
    "\n",
    "令 $R$ 為 $A$ 的最簡階梯形式矩陣。  \n",
    "我們把領導變數拉到左邊、自由變數拉到右邊  \n",
    "（最後求完解以後再把變數順序拉回來就好），  \n",
    "因此我們可以假設 $R$ 的非零列長得像 $R' = \\begin{bmatrix} I_r & Y \\end{bmatrix}$。  \n",
    "我們把每個 $\\mathbb{R}^n$ 的向量都寫成 $({\\bf v}_1, {\\bf v}_2)$ 使得 ${\\bf v}_1\\in\\mathbb{R}^r$ 而 ${\\bf v}_2\\in\\mathbb{R}^{n-r}$。  \n",
    "說明 \n",
    "$$\\operatorname{ker}(A) = \\operatorname{ker}(R') = \\{(-Y{\\bf v}_2, {\\bf v}_2): {\\bf v}_2\\in\\mathbb{R}^{n-r}\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5(b)\n",
    "\n",
    "令 $H$ 為一 $n\\times (n-r)$ 的矩陣﹐  \n",
    "其各行向量是由 $\\beta_K$ 中的向量組成。  \n",
    "觀察到  $H = \\begin{bmatrix} -Y \\\\ I_{n-r} \\end{bmatrix}$。  \n",
    "\n",
    "說明 $H{\\bf v}_2 = (-Y{\\bf v}_2, {\\bf v}_2)$、  \n",
    "因此 $\\operatorname{ker}(A) = \\operatorname{Col}(H) = \\operatorname{span}(\\beta_K)$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5(c)\n",
    "\n",
    "藉由 $H^\\top$ 和 $R'$ 的形式的相似性，  \n",
    "說明 $\\operatorname{ker}(H^\\top) = \\operatorname{Col}(R'^\\top)$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5(d)\n",
    "\n",
    "若 $S\\subseteq\\mathbb{R}^n$ 是一群有限個數的向量而 $V = \\operatorname{span}(S)$。  \n",
    "證明 $(V^\\perp)^\\perp = V$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6\n",
    "\n",
    "令 $A$ 為一 $m\\times n$ 矩陣。  \n",
    "令 ${\\bf u}_1,\\ldots,{\\bf u}_n$ 為 $A$ 的各行向量。  \n",
    "接下來我們說明 $\\operatorname{Col}(A) = \\operatorname{span}(\\beta_C)$ 及 $\\operatorname{ker}(A^\\top) = \\operatorname{span}(\\beta_L)$。  \n",
    "令 $\\left[\\begin{array}{c|c} R & B \\end{array}\\right]$ 為 $\\left[\\begin{array}{c|c} A & I_m \\end{array}\\right]$ 的最簡階梯形式矩陣。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6(a)\n",
    "\n",
    "令 $\\beta_K = \\{{\\bf h}_1,\\ldots,{\\bf h}_{n-r}\\}$。  \n",
    "令 $j$ 為 $R$ 的第 $i$ 個軸。  \n",
    "藉由 $A{\\bf h}_i = {\\bf 0}$ 來說明 ${\\bf u}_j\\in\\operatorname{span}(\\beta_C)$、  \n",
    "並證明 $\\operatorname{Col}(A) = \\operatorname{span}(\\beta_C)$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6(b)\n",
    "\n",
    "令 $\\hat{R}$ 為 $R$ 中對應到軸的那幾個行向量所組成的 $m\\times r$ 矩陣。  \n",
    "令 $\\hat{A}$ 為 $A$ 中對應到 $R$ 的軸的那幾個行向量所組成的 $m\\times r$ 矩陣。  \n",
    "藉由 $\\operatorname{ker}(\\hat{R}) = \\{{\\bf 0}\\}$ 來說明 $\\operatorname{ker}(\\hat{A}) = \\{{\\bf 0}\\}$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6(c)\n",
    "\n",
    "接著我們說明 $\\beta_C$ 和 $\\beta_L$ 中的向量互相垂直。  \n",
    "\n",
    "令 ${\\bf e}_1,\\ldots,{\\bf e}_n$ 為 $I_n$ 中的行向量。  \n",
    "觀察到  \n",
    "$$\\left[\\begin{array}{c|c} A & I_m \\end{array}\\right] \\begin{bmatrix} {\\bf e}_i \\\\ -{\\bf u}_i \\end{bmatrix} = {\\bf 0}.$$\n",
    "利用這個性質推得 $R{\\bf e}_i = B{\\bf u}_i$ 並說明 ${\\bf u}_i$ 和 $\\beta_L$ 中的各向量垂直。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6(d)\n",
    "\n",
    "由前一題我們已知 $\\operatorname{Col}(A)^\\perp \\supseteq \\operatorname{span}(\\beta_L)$。  \n",
    "接著我們證明 $\\operatorname{Col}(A)^\\perp \\subseteq \\operatorname{span}(\\beta_L)$。  \n",
    "令 ${\\bf b}\\in\\operatorname{Col}(A)^\\perp$ 則 ${\\bf b}^\\top A = {\\bf 0}$。  \n",
    "考慮 ${\\bf v}^\\top = {\\bf b}^\\top \\left[\\begin{array}{c|c} A & I_m \\end{array}\\right] = \n",
    "\\left[\\begin{array}{c|c} {\\bf 0}^\\top & {\\bf b}^\\top\\end{array}\\right]$。  \n",
    "說明 ${\\bf v}^\\top$ 也落在 $\\left[\\begin{array}{c|c} R & B \\end{array}\\right]$ 的列空間中﹐進而說明 ${\\bf b}\\in\\operatorname{span}(\\beta_L)$。  \n",
    "\n",
    "因為 $\\operatorname{Col}(A)^\\perp = \\operatorname{ker}(A^\\top)$﹐  \n",
    "所以 $\\operatorname{ker}(A^\\top) = \\operatorname{span}(\\beta_L)$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6(e)\n",
    "\n",
    "其實我們也可以證明 $\\operatorname{ker}(A^\\top)^\\perp = \\operatorname{Col}(A)$。  \n",
    "如此一來可以再次說明 $(V^\\perp)^\\perp = V$。  \n",
    "\n",
    "因為我已知 $\\operatorname{ker}(A^\\top)^\\perp \\supseteq \\operatorname{Col}(A)$。  \n",
    "接著我們證明 $\\operatorname{ker}(A^\\top)^\\perp \\subseteq \\operatorname{Col}(A)$。  \n",
    "令 ${\\bf b}\\in\\operatorname{ker}(A^\\top)^\\perp$ 因此 $B{\\bf b}$ 的最後 $m-r$ 項都是 $0$。  \n",
    "說明存在 ${\\bf v}\\in\\mathbb{R}^n$ 使得  \n",
    "$$\\left[\\begin{array}{c|c} R & B \\end{array}\\right] \\begin{bmatrix} {\\bf v} \\\\ {\\bf b} \\end{bmatrix} = {\\bf 0}.$$  \n",
    "因此 $A{\\bf v} + I_m{\\bf b} = {\\bf 0}$﹐得到 ${\\bf b}\\in\\operatorname{Col}(A)$。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 7\n",
    "\n",
    "若 $S\\subseteq\\mathbb{R}^n$ 是一群有限個數的向量而 $V = \\operatorname{span}(S)$。  \n",
    "依照以下步驟證明：  \n",
    "任何向量 ${\\bf b}\\in\\mathbb{R}^n$ 都可以寫成 ${\\bf b} = {\\bf w} + {\\bf h}$  \n",
    "使得 ${\\bf w}\\in V$ 且 ${\\bf h}\\in V^\\perp$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 7(a)\n",
    "\n",
    "令 $A_S$ 為一矩陣其各行向量由 $S$ 的各向量組成﹐  \n",
    "並算出其 $\\beta_C$。  \n",
    "令 $A$ 為 $A_S$ 中只留 $\\beta_C$ 中向量的子矩陣。  \n",
    "由前一題我們知道 $\\operatorname{Col}(A_S) = \\operatorname{Col}(A) = V$  \n",
    "且 $\\operatorname{ker}(A) = \\{{\\bf 0}\\}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 7(b)\n",
    "\n",
    "說明 $A^\\top A$ 可逆。  \n",
    "同時驗證  \n",
    "$$\\begin{aligned}  \n",
    " {\\bf w} &= A(A^\\top A)^{-1}A^\\top {\\bf b}, \\\\\n",
    " {\\bf h} &= {\\bf b} - {\\bf w}\n",
    "\\end{aligned}$$\n",
    "符合我們要的條件。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 7(c)\n",
    "\n",
    "證明 ${\\bf b}$ 寫成 ${\\bf w} + {\\bf h}$ 的方法唯一。  \n",
    "也就是說﹐如果 ${\\bf b} = {\\bf w}_1 + {\\bf h}_1 = {\\bf w}_2 + {\\bf h}_2$  \n",
    "使得 ${\\bf h}_1,{\\bf h}_2\\in V$ 且 ${\\bf w}_1,{\\bf w}_2\\in V^\\perp$﹐  \n",
    "則 ${\\bf h}_1 = {\\bf h}_2$ 且 ${\\bf w}_1 = {\\bf w}_2$。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.4",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
